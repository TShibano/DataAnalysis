{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c195dc9d-8814-4f04-b633-634ecca5cfaa",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "Data does not always come in its final processed form that is required for training machine learning algorithms.\n",
    "We use transforms to perform some manipulation of the data and make it suitable for training.\n",
    "\n",
    "All TorchVision datasets have two parameters - `transform` to modify the features and `target_transform` to modify the labels - that accept callables containing the transformation logic.\n",
    "The [tochvision.transforms](https://pytorch.org/vision/stable/transforms.html) module offeres several commonly-used transforms out of the box.\n",
    "\n",
    "The FashionMNIST features are in PIL Image format, and the labels are integers.\n",
    "For training, we need the features as normalized tensors, and the labels as one-hot encoded tensors.\n",
    "To make these transformations, we use `ToTensor` and `Lambda`.\n",
    "\n",
    "データは常に機械学習アルゴリズムのために必要な，最終的に整形された形をしているわけではない．\n",
    "transformsを使うことで，データの操作を行い，訓練に適したデータにすることができる．\n",
    "\n",
    "TorchVisionデータセットは全て，二つのパラメータ`transform`と`target_transform`を持っていて，変換ロジックを含んだ呼び出し可能オブジェクトを受け入れる．．\n",
    "`transform`は特徴量を変換し，`target_transform`はラベルを変換する．\n",
    "torchvision.transformsモジュールは，すぐに使うことができる一般的に用いられている変換方法を提供できる．\n",
    "\n",
    "FashionMNISTの特徴量(入力)はPIL Imageフォーマットであり，ラベルは数値である．\n",
    "訓練のために，特徴量は標準化されたtensorが，ラベルはワンホットエンコードされたtensorが必要である．\n",
    "これらを変換するために，`ToTensor`と`Lambda`を用いる．\n",
    "\n",
    "#### 補足\n",
    "PIL Image\n",
    "\n",
    "Python Image Libraryのことであり，Pythonのインタプリタで画像を処理するためのライブラリである．\n",
    "様々なファイル形式をサポートし，効率的な内部表現，強力な画像処理機能がある．\n",
    "その後，Pillowに移植された．詳細は[Pillowのウェブサイト]．(https://pillow.readthedocs.io/en/stable/index.html#)．\n",
    "\n",
    "ワンホットエンコード\n",
    "\n",
    "カテゴリ変数があった場合，例えばlabel1, label2, label3とあるとする．\n",
    "この時，以下のテーブルのように表記することを指す．\n",
    "\n",
    "|category|label1|label2|label3|\n",
    "|--------|------|------|------|\n",
    "|label1  |1     |0     |0     |\n",
    "|lebal2  |0     |1     |0     |\n",
    "|label3  |0     |0     |1     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d4ff38-5b47-4bb4-934c-fec45d15fccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "print(torchvision.__version__)\n",
    "df = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(\n",
    "        lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8107bab-fb2e-4338-aef4-d850af4c16e7",
   "metadata": {},
   "source": [
    "## ToTensor()\n",
    "[ToTensor](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor) converts a PIL image or NumPy `ndarray` into a `FloatTensor`, and scales the image's pixel intensity values in the range\\[0., 1.\\]\n",
    "\n",
    "ToTensorはPIL画像やNumPyの`ndarray`を`FlaotTensor`に変換し，画像のピクセル強度値を\\[0., 1.\\]の範囲でスケーリングする．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fa0c6b-3100-42f8-ad87-651a013e72d8",
   "metadata": {},
   "source": [
    "## Lambda Transforms\n",
    "Lambda transforms apply any user-defined lambda function.\n",
    "Here, we define a function to turn the integer into a one-hot encoded tensor.\n",
    "It first creates a zero tensor of size 10 (the number of labels in our dataset) and calls \n",
    "[scatter_](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.scatter_) which assigns a `value=1` on the index as given by the label `y`.\n",
    "\n",
    "Lambda変換はユーザが定義したlambda関数を適用する．\n",
    "ここでは，数値をワンホットエンコードされたtensorに変換する関数を定義した．\n",
    "サイズ10のtensorを0で初期化し，ラベル`y`に応じたインデックスに`value=1`を適応する`scatter_`関数を呼び出した．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2176429-fa4c-4fbf-86db-32a5b23e1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b620f53-4ae6-4d45-8e0c-49f7f1ca6bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "label1 = 0\n",
    "label3 = 2\n",
    "t = Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
    "print(t(label1))\n",
    "print(t(label3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
