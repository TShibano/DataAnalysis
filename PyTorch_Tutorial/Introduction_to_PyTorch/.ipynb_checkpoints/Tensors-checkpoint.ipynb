{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed6f417-fa04-474a-ba30-ad5879b1d45a",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "[URL](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html)\n",
    "\n",
    "\n",
    "Tensors are a specialized data structure that are very similar to arrays and matrices.\n",
    "In PyTorch, we use tensors to encode the inputs and outputs of model, as well as the model's parameters/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacde876-845e-43bc-9a5d-dabd8e813e00",
   "metadata": {},
   "source": [
    "Tensors are similar to NumPy's ndarrays, except that tensors can run on GPUs or other hardware accelerators.\n",
    "In fact, tesnsors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see [Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)).\n",
    "Tensors are also optimized for automatic differentiation (we'll see more about that later in the Autograd section).\n",
    "If you're familiar with ndarrays, you'll be right at home with the Tensor API. \n",
    "If not follow along!\n",
    "\n",
    "\n",
    "- tensorsとNumPyはとても似ていて，違う点はGPUやその他のハードウェアアクセラレーションを利用できるかどうか．\n",
    "- メモリも共有しており，データをコピーする必要がない．(無駄にメモリを消費しない?)\n",
    "- tensorsは自動微分のために最適化される．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24fbccc1-4551-4df5-8f92-d36fd3f18bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e711cef-4f89-4e13-bd82-83821b5b3bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.8.1\n",
      "np: 1.20.2\n"
     ]
    }
   ],
   "source": [
    "print(f'torch: {torch.__version__}')\n",
    "print(f'np: {np.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fecb81a-8b67-4a8c-84d7-7bf45649b5e6",
   "metadata": {},
   "source": [
    "## Initializing a Tensor\n",
    "Tensors can be initialized in various ways.\n",
    "\n",
    "tesorは様々な方法で初期化出来る．\n",
    "直接変換したり，numpy形式や別のtensorからも可能である"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3ccf6-86a4-4754-8475-a03541e0bcd8",
   "metadata": {},
   "source": [
    "### Directly from data\n",
    "Tensors can be created directly from data.\n",
    "The data type is automatically inferred.\n",
    "\n",
    "tensorはデータから直接作ることができる．\n",
    "データタイプは自動的に推論されて決まる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a7fa80-02ec-4965-ae16-ca279127c453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directly from data\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d420e78a-d7be-4352-8ed4-10699507a7b6",
   "metadata": {},
   "source": [
    "### From a NumPy array\n",
    "Tensors can be created from NumPy arrays (and vice versa - see [Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label))\n",
    "\n",
    "tensorはNumPyからも可能．詳細はURLを確認する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde269f5-39d4-4f41-8c9b-af0ec67f99a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From a NumPy array\n",
    "np_array = np.array([[1, 2], [3, 4]])\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1f926-9eec-445e-8b6c-a9b253af7c38",
   "metadata": {},
   "source": [
    "### From another tensor\n",
    "The new tensor retains the proprties (sahpe, datatype) of the argument tensor, unless explicitly overridden.\n",
    "\n",
    "明示的に上書きしない限り，新しいtensorは元のtensorの引数の性質(形やデータタイプ)を維持する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e3cdc90-dbd7-4238-89fe-a049e493a884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor:\n",
      " tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "Random Tensor: \n",
      " tensor([[0.5150, 0.2971],\n",
      "        [0.6060, 0.6592]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retians the properties of x_data\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(f'Ones Tensor:\\n {x_ones}')\n",
    "\n",
    "# overrides the datatype pf x_data\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float32)\n",
    "print(f'Random Tensor: \\n {x_rand} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb6453-4d1c-4be2-ac8d-a971956d70ce",
   "metadata": {},
   "source": [
    "### With random or constant value\n",
    "`shape` is a tuple of tensor dimensions.\n",
    "In the functions below, it determines the dimensionality of the output tensor.\n",
    "\n",
    "`shape`はtensorの次元を表したタプルである．\n",
    "以下の関数を用いれば，出力されるtensorの次元を決定することができる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cf3f485-224e-46fe-91c7-f8ea63e5ae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.2763, 0.6561],\n",
      "        [0.0277, 0.3908]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1.],\n",
      "        [1., 1.]]) \n",
      "\n",
      "Zeors Tensor: \n",
      " tensor([[0., 0.],\n",
      "        [0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 2, )\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f'Random Tensor: \\n {rand_tensor} \\n')\n",
    "print(f'Ones Tensor: \\n {ones_tensor} \\n')\n",
    "print(f'Zeors Tensor: \\n {zeros_tensor} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fed846e7-75a1-490f-b41d-fd91a76b8b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (2): \n",
      " tensor([1., 1.])\n",
      "\n",
      "shape (2, 3):\n",
      "  tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "shape (2, 3, 4)):\n",
      "  tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "\n",
      "shape (2, 3, ):\n",
      "  tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.ones((2))        # 2 vector\n",
    "tensor2 = torch.ones((2, 3))     # 2x3 matrix\n",
    "tensor3 = torch.ones((2, 3, 4))  # 2x3x4 tensor\n",
    "tensor4 = torch.ones((2, 3, ))   # 2x3 matrix\n",
    "print(f'shape (2): \\n {tensor1}\\n')\n",
    "print(f'shape (2, 3):\\n  {tensor2}\\n')\n",
    "print(f'shape (2, 3, 4)):\\n  {tensor3}\\n')\n",
    "print(f'shape (2, 3, ):\\n  {tensor4}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb77d68-05e4-4887-b063-f1268ec13800",
   "metadata": {},
   "source": [
    "## Attributes of a Tensor\n",
    "Tensor attributes descrive their shape, datatype, and the device on which they are stored.\n",
    "\n",
    "tensorのアトリビュートには，shape, datatype, device(保存されている場所を示す)がある．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "851b5e35-de19-4d69-a45e-bb53b739e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5872, 0.8028, 0.5084, 0.9690],\n",
      "        [0.5210, 0.9562, 0.8006, 0.3064],\n",
      "        [0.9844, 0.2014, 0.6365, 0.6765]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "print(tensor)\n",
    "print(f'Shape of tensor: {tensor.shape}')\n",
    "print(f'Datatype of tensor: {tensor.dtype}')\n",
    "print(f'Device tensor is stored on: {tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd92ac-d44d-4410-ab31-d40bd0a60545",
   "metadata": {},
   "source": [
    "## Operation on Tensors\n",
    "Over 100 tensor operation, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing), sampling and more are comprehensively descrived [here](https://pytorch.org/docs/stable/torch.html)\n",
    "\n",
    "Each of these operation can be run on the GPU.\n",
    "\n",
    "By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using `.to` method (after checking for GPU availability).\n",
    "Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!\n",
    "\n",
    "tensor型を操作する方法はたくさんあり，算術や線形代数，行列操作などがある．\n",
    "詳細はURLに載っている．\n",
    "それぞれの操作はGPU上で行うことができる．\n",
    "デフォルトでは，tensorはCPU上で作成されるため，GPUが使えるかを確認したのちに，`.to`メソッドを用いて，明示的にGPU上に移動させる必要がある．\n",
    "大きいtensorをデバイス間で移動することは，時間やメモリの観点からコストがかかることに注意する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ccd8810-51a8-4bbc-868c-288c3326f0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'now using device: {device}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "    tensor = tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16c827-6040-45e3-b21e-9c00174b4028",
   "metadata": {},
   "source": [
    "Try out some of the operation from the list.\n",
    "If you're familiar with the NumPy API, you'll find the Tensor API a breeze to use.\n",
    "\n",
    "NumPyの操作に慣れていれば，tensorの操作も簡単にできる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93928c0-6f5f-4ff5-bc38-60ac9bc18afa",
   "metadata": {},
   "source": [
    "### Standard numpy-like indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1d648b3-201b-4b6c-9f43-944b47c3c9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "First row: \n",
      " tensor([1., 1., 1.])\n",
      "\n",
      "First column: \n",
      " tensor([1., 1., 1., 1.]) \n",
      "\n",
      "Last column: \n",
      " tensor([1., 1., 1., 1.]) \n",
      " \n",
      "tensor([[1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones((4, 3))\n",
    "print(f'tensor: \\n {tensor}\\n')\n",
    "print(f'First row: \\n {tensor[0]}\\n')\n",
    "print(f'First column: \\n {tensor[:, 0]} \\n')\n",
    "print(f'Last column: \\n {tensor[:, -1]} \\n ')\n",
    "\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23291adf-0746-4f31-902e-43b4c6ccf5ef",
   "metadata": {},
   "source": [
    "### Joining tensors\n",
    "You can use `torch.cat` to concatenate a sequence of tensors along a given dimension.\n",
    "See also [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html), another tensor joining op(up?) that is subtly different from `torch.cat`.\n",
    "\n",
    "`torch.cat`を使えば，指定した次元に対してtensorを結合することができる．\n",
    "`torch.stack`は，新しい次元に沿ってtensorを結合させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eea3ca75-7d23-458c-af7f-783849de240b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: \n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) \n",
      "\n",
      "t1: \n",
      " tensor([[1., 2., 3., 1., 2., 3., 1., 2., 3.],\n",
      "        [4., 5., 6., 4., 5., 6., 4., 5., 6.]]) \n",
      "\n",
      "t0: \n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [1., 2., 3.],\n",
      "        [4., 5., 6.]]), \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(f't: \\n {t} \\n')\n",
    "\n",
    "# torch.cat(tensor, dim=1) -> 列に追加(concatenate column)\n",
    "t1 = torch.cat([t, t, t], dim=1)\n",
    "print(f't1: \\n {t1} \\n')\n",
    "\n",
    "# torch.cat(tensor, dim=0) -> 行に追加(concatenate row)\n",
    "t0 = torch.cat([t, t, t], dim=0)\n",
    "print(f't0: \\n {t0}, \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a7402e6-7b7a-4cbb-8d6a-32fc85676afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts1: \n",
      " tensor([[[1., 2., 3.],\n",
      "         [1., 2., 3.],\n",
      "         [1., 2., 3.]],\n",
      "\n",
      "        [[4., 5., 6.],\n",
      "         [4., 5., 6.],\n",
      "         [4., 5., 6.]]]) \n",
      "\n",
      "ts0: \n",
      " tensor([[[1., 2., 3.],\n",
      "         [4., 5., 6.]],\n",
      "\n",
      "        [[1., 2., 3.],\n",
      "         [4., 5., 6.]],\n",
      "\n",
      "        [[1., 2., 3.],\n",
      "         [4., 5., 6.]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# torch.stack(tensor, dim=1) -> 行ごとに追加する\n",
    "ts1 = torch.stack([t, t, t], dim=1)\n",
    "print(f'ts1: \\n {ts1} \\n')\n",
    "\n",
    "# torch.stack(tensor, dim=0) -> 一つの塊として追加する\n",
    "ts0 = torch.stack([t, t, t], dim=0)\n",
    "print(f'ts0: \\n {ts0} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ace5e-91ce-45f3-a840-f94e8f234922",
   "metadata": {},
   "source": [
    "### Single-element tensors\n",
    "If you have a one-element tensor, for example by aggregating all value of a tensor into one value, you can convert it to a Python numerical value using `item()`.\n",
    "\n",
    "もしtensorが一つの要素しかない場合(集計など)は，`item()`を使えば，Pythonの数値型として取得できる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f56220dd-655a-4617-926e-e88eb0909739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4555, 0.1349, 0.2650, 0.3512],\n",
      "        [0.7351, 0.2268, 0.9525, 0.7250],\n",
      "        [0.1857, 0.6891, 0.9155, 0.9184]])\n",
      "agg: 6.5546793937683105, type(agg): <class 'torch.Tensor'>\n",
      "agg_item: 6.5546793937683105, type(agg_item): <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((3, 4))\n",
    "print(tensor)\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(f'agg: {agg}, type(agg): {type(agg)}')\n",
    "print(f'agg_item: {agg_item}, type(agg_item): {type(agg_item)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541118bc-90ad-4bbe-a95c-e750f6751ad3",
   "metadata": {},
   "source": [
    "### In-place operating\n",
    "Operations that store the result into the operand are called in-place.\n",
    "They are denoted by `_` suffix.\n",
    "For example: `x.copy_(y)`, `x.t_()`, will change `x`\n",
    "\n",
    "結果をオペランド(: 演算の対象となるもの)に保存する操作は，インプレースという．\n",
    "接尾辞`_`で表現する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6789f2f-4bfb-464f-bdbc-5823973ec8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones((2, 3))\n",
    "print(tensor, '\\n')\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9783eff4-e089-428a-bc63-8a57872c5c98",
   "metadata": {},
   "source": [
    "#### Note\n",
    "In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history.\n",
    "Hence, their use is discourage.\n",
    "\n",
    "インプレース操作はメモリを節約するが，履歴はすぐに失われるため，導関数(derivative)を計算する時に問題が発生する可能性がある．\n",
    "よって使用をお勧めしない．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c15be-3b0d-42c3-a6cc-f9fbe1c72e42",
   "metadata": {},
   "source": [
    "## Bridge with NumPy\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other.\n",
    "\n",
    "CPU上とのtensorとNumPy arrayはメモリの位置を共有することができ，片方を変えればもう片方も変わる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25484bff-5a82-4ecc-a19d-81aa8ef33855",
   "metadata": {},
   "source": [
    "### Tensor to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0db89ff-9553-41fc-9f3a-763f0e364f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f't: {t}')\n",
    "n = t.numpy()\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb5ac50-5620-4801-adb6-23143dd6dd34",
   "metadata": {},
   "source": [
    "A change in the tenosr reflects in the NumPy array.\n",
    "\n",
    "tensorの変換はnumpyに反映される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ecebe0e7-c8e1-433e-a712-2ae13cdea66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f't: {t}')\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb04371-cf92-420b-bb63-edc91e8561b9",
   "metadata": {},
   "source": [
    "### NumPy array to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d68a0be-aa82-4b7d-b6c1-d66a62d7417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "print(f't: {t}')\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ad2bc-640d-4df4-b957-ed6a80ac4adf",
   "metadata": {},
   "source": [
    "Changes in the NumPy array reflects in the tensor.\n",
    "\n",
    "NumPyの変換はtensorにも反映される．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04199e93-58ec-4803-8531-ce94a1add299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f't: {t}')\n",
    "print(f'n: {n}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
